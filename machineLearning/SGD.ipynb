{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2560, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=4)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:95: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=100, validation_data=<keras.pre..., callbacks=[<keras.ca..., validation_steps=4000, steps_per_epoch=200)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 41s - loss: 0.5190 - acc: 0.7870 - val_loss: 0.3281 - val_acc: 0.9000\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 40s - loss: 0.2152 - acc: 0.9355 - val_loss: 0.2828 - val_acc: 0.9085\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 40s - loss: 0.1987 - acc: 0.9430 - val_loss: 0.2330 - val_acc: 0.9504\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 40s - loss: 0.1690 - acc: 0.9500 - val_loss: 0.2156 - val_acc: 0.9414\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 40s - loss: 0.1465 - acc: 0.9580 - val_loss: 0.2263 - val_acc: 0.9415\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 40s - loss: 0.1558 - acc: 0.9615 - val_loss: 0.1632 - val_acc: 0.9585\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 40s - loss: 0.1363 - acc: 0.9580 - val_loss: 0.2286 - val_acc: 0.9499\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 40s - loss: 0.1354 - acc: 0.9650 - val_loss: 0.3624 - val_acc: 0.9334\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 40s - loss: 0.1245 - acc: 0.9660 - val_loss: 0.2782 - val_acc: 0.9417\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 40s - loss: 0.1285 - acc: 0.9625 - val_loss: 0.3218 - val_acc: 0.9500\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "##### Building the CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3),activation = 'relu'))\n",
    "\n",
    "\n",
    "# Step 2 - Max Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a second convolution layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a third convolution layer\n",
    "classifier.add(Convolution2D(2560, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 4th convolution layer\n",
    "classifier.add(Convolution2D(256, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 5th convolution layer\n",
    "#classifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 6th convolution layer\n",
    "#classifier.add(Convolution2D(256, 3, 3, activation = 'relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 5th convolution layer\n",
    "#classifier.add(Convolution2D(512, 3, 3, activation = 'relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "classifier.add(Dense(output_dim = 128, activation= 'relu'))\n",
    "classifier.add(Dense(output_dim = 4,activation= 'softmax'))\n",
    "\n",
    "\n",
    "# Compiling the CNN\n",
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.05, momentum=0.0, decay=0.0, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "adamax = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08, schedule_decay=0.004)\n",
    "adagrad = optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
    "rmsprop = optimizers.RMSprop(lr=0.05, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "tfo = optimizers.TFOptimizer(rmsprop)\n",
    "classifier.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'C:\\\\demo6\\\\TrainingData',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'C:\\\\demo6\\\\ValidationData',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=2,\n",
    "        class_mode='categorical')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=3, verbose=1, mode='max')\n",
    "\n",
    "classifier.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=2000,     \n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[early_stopping],\n",
    "        validation_steps=4000)\n",
    "classifier.save('C:\\\\demo6\\\\clipRun.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
