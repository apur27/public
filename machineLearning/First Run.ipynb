{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(5120, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=5)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 499 images belonging to 5 classes.\n",
      "Found 150 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=50, validation_data=<keras.pre..., callbacks=[<keras.ca..., validation_steps=800, steps_per_epoch=200)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 94s - loss: 12.8434 - acc: 0.1992 - val_loss: 12.8844 - val_acc: 0.2006\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 93s - loss: 12.8873 - acc: 0.2004 - val_loss: 12.8844 - val_acc: 0.2006\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 91s - loss: 12.8873 - acc: 0.2004 - val_loss: 12.9146 - val_acc: 0.1988\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 93s - loss: 12.8891 - acc: 0.2003 - val_loss: 12.8844 - val_acc: 0.2006\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 91s - loss: 12.8855 - acc: 0.2006 - val_loss: 12.8743 - val_acc: 0.2013\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 93s - loss: 12.8864 - acc: 0.2005 - val_loss: 12.8743 - val_acc: 0.2013\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 91s - loss: 12.8891 - acc: 0.2003 - val_loss: 12.8844 - val_acc: 0.2006\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 91s - loss: 12.8855 - acc: 0.2006 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 91s - loss: 12.8882 - acc: 0.2004 - val_loss: 12.9247 - val_acc: 0.1981\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 91s - loss: 12.8891 - acc: 0.2003 - val_loss: 12.9247 - val_acc: 0.1981\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 90s - loss: 12.8891 - acc: 0.2003 - val_loss: 12.8945 - val_acc: 0.2000\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(12, 3, 3, input_shape = (64, 64, 3),activation = 'relu'))\n",
    "\n",
    "\n",
    "# Step 2 - Max Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a second convolution layer\n",
    "classifier.add(Convolution2D(5120, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a third convolution layer\n",
    "classifier.add(Convolution2D(512, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 4th convolution layer\n",
    "classifier.add(Convolution2D(256, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 5th convolution layer\n",
    "#classifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 6th convolution layer\n",
    "#classifier.add(Convolution2D(256, 3, 3, activation = 'relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Adding a 5th convolution layer\n",
    "#classifier.add(Convolution2D(512, 3, 3, activation = 'relu'))\n",
    "#classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "# Step 4 - Full Connection\n",
    "classifier.add(Dense(output_dim = 128, activation= 'relu'))\n",
    "classifier.add(Dense(output_dim = 5,activation= 'softmax'))\n",
    "\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '/darrenDemo3/TrainingData',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=10,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        '/darrenDemo3/ValidationData',\n",
    "        target_size=(64, 64),\n",
    "        batch_size=2,\n",
    "        class_mode='categorical')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='max')\n",
    "from keras.callbacks import TensorBoard\n",
    "tbCallBack = TensorBoard(log_dir='/darrenDemo3/tb', histogram_freq=2,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "classifier.fit_generator(\n",
    "        train_generator,\n",
    "        samples_per_epoch=2000,     \n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[early_stopping, tbCallBack],\n",
    "        validation_steps=800)\n",
    "classifier.save('/darrenDemo3/Q09-model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
